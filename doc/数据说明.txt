数据说明文档：
Lily
1.训练数据，训练数据来源于搜狗语料库数据（精简版一个月数据），保存在reduced文件夹中。存储为不同的txt文件。一共有大概37万余条新闻数据！
由于一些类别的数据过多，所以对数据进行负采样和重采样，即超过20000条数据的类型只取20000条数据，低于5000条数据的类别进行重采样至5000条数据，其他类型的数据不作处理，
保证训练数据样本类别较为均衡，减少训练误差。
我们通过data_process的data_catch.py中的clean_data函数对原始数据进行处理，包括从url链接中提取出对应的类别以及从标签中提取出正文并做初步清洗，
去除缺失值和正文小于一定长度的记录。正文保存在data/content文件夹下，标题保存在data/title文件夹下。均为按照不同的类别进行存储为txt文件。
原始语料库一共有15个类别，有一个类别为2008，为无效类别，因此我们将次类别的文件剔除，存储在2008文件夹中。
数据链接：http://www.sogou.com/labs/resource/ftp.php?dir=/Data/SogouCS/SogouCS.reduced.tar.gz（精简版搜狐新闻一个月数据）

2.data_process的data_process_train.py文件运行，对分类整理好的新闻文本进行分词，去停词，清晰完善，并且为文本打上不同的类别数字标签，同时建立
数字标签和相应类别的字典，new_dict并存储为txt文件。

3.测试数据直接保存在data文件下的test_data.csv文件中，包含所有的字段。测试时根据data_process_eval.py的data_test函数处理，并且读入内存。